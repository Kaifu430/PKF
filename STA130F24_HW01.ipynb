{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STA130F24_HW01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qustion 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_n           0\n",
       "id              1\n",
       "name            0\n",
       "gender          0\n",
       "species         0\n",
       "birthday        0\n",
       "personality     0\n",
       "song           11\n",
       "phrase          0\n",
       "full_id         0\n",
       "url             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['row_n', 'id', 'name', 'gender', 'species', 'birthday', 'personality',\n",
      "       'song', 'phrase', 'full_id', 'url'],\n",
      "      dtype='object')\n",
      "(391, 11)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 391 entries, 0 to 390\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   row_n        391 non-null    int64 \n",
      " 1   id           390 non-null    object\n",
      " 2   name         391 non-null    object\n",
      " 3   gender       391 non-null    object\n",
      " 4   species      391 non-null    object\n",
      " 5   birthday     391 non-null    object\n",
      " 6   personality  391 non-null    object\n",
      " 7   song         380 non-null    object\n",
      " 8   phrase       391 non-null    object\n",
      " 9   full_id      391 non-null    object\n",
      " 10  url          391 non-null    object\n",
      "dtypes: int64(1), object(10)\n",
      "memory usage: 33.7+ KB\n",
      "None\n",
      "   row_n       id     name  gender    species birthday personality  \\\n",
      "0      2  admiral  Admiral    male       bird     1-27      cranky   \n",
      "1      3  agent-s  Agent S  female   squirrel      7-2       peppy   \n",
      "2      4    agnes    Agnes  female        pig     4-21        uchi   \n",
      "3      6       al       Al    male    gorilla    10-18        lazy   \n",
      "4      7  alfonso  Alfonso    male  alligator      6-9        lazy   \n",
      "\n",
      "          song    phrase           full_id  \\\n",
      "0   Steep Hill   aye aye  villager-admiral   \n",
      "1      DJ K.K.  sidekick  villager-agent-s   \n",
      "2   K.K. House   snuffle    villager-agnes   \n",
      "3   Steep Hill   Ayyeeee       villager-al   \n",
      "4  Forest Life  it'sa me  villager-alfonso   \n",
      "\n",
      "                                                 url  \n",
      "0  https://villagerdb.com/images/villagers/thumb/...  \n",
      "1  https://villagerdb.com/images/villagers/thumb/...  \n",
      "2  https://villagerdb.com/images/villagers/thumb/...  \n",
      "3  https://villagerdb.com/images/villagers/thumb/...  \n",
      "4  https://villagerdb.com/images/villagers/thumb/...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "print(df.columns)\n",
    "print(df.shape)\n",
    "print(df.info())\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.2\n",
    "In the context of the **Animal Crossing dataset**,:\n",
    "\n",
    "### 1. **Observations**:\n",
    "- **Definition**: An observation refers to a single data entry or record in the dataset. It represents an individual instance or unit of analysis.\n",
    "- **In the Animal Crossing Dataset**: Each observation would typically correspond to a **specific character, item, or event** in the game. For example:\n",
    "  - If the dataset contains a list of Animal Crossing villagers, **each villager would be an observation**.\n",
    "  - If it's a dataset about items in the game, then **each item** (like a piece of furniture, clothing, etc.) would be an observation.\n",
    "\n",
    "  Observations are organized as rows in a dataset. Each row in the dataset contains information related to a particular villager, item, or event.\n",
    "\n",
    "### 2. **Variables**:\n",
    "- **Definition**: A variable refers to a characteristic, feature, or attribute that you are measuring or recording about our observations. Variables represent different types of data for each observation.\n",
    "- **In the Animal Crossing Dataset**: Variables could include:\n",
    "  - For villagers: `Name`, `Species`, `Personality`, `Birthday`, `Catchphrase`, etc.\n",
    "  - For items: `Name`, `Type`, `Price`, `Sell Price`, `Color`, etc.\n",
    "  \n",
    "  Variables are organized as columns in a dataset. Each column provides specific information about all observations (rows).\n",
    "\n",
    "### Example:\n",
    "\n",
    "Letâ€™s say you have a small dataset of Animal Crossing villagers. It might look something like this:\n",
    "\n",
    "| **Name**   | **Species** | **Personality** | **Birthday** | **Catchphrase** |\n",
    "|------------|-------------|-----------------|--------------|-----------------|\n",
    "| Bob        | Cat         | Lazy            | January 1st  | \"purr\"          |\n",
    "| Isabelle   | Dog         | Peppy           | December 20th| \"woof\"          |\n",
    "| Apollo     | Eagle       | Cranky          | July 4th     | \"pah\"           |\n",
    "\n",
    "In this dataset:\n",
    "- **Observations**: Each row (Bob, Isabelle, Apollo) represents an observation (a unique villager).\n",
    "- **Variables**: The columns (`Name`, `Species`, `Personality`, `Birthday`, `Catchphrase`) are the variables.\n",
    "\n",
    "In summary:\n",
    "- **Observations** = individual entries (villagers/items/events).\n",
    "- **Variables** = attributes or characteristics recorded for each observation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaction with Chatbot:\n",
    "\n",
    "\n",
    "**Summary of Interactions with Chatbot Regarding Animal Crossing Dataset**\n",
    "\n",
    "**Objective**: I downloaded a dataset related to characters from the game \"Animal Crossing\" and wanted to explore the columns of information present, as well as understand the size of the dataset.\n",
    "\n",
    "---\n",
    "\n",
    "**Interaction 1**: \n",
    "- I provided a link to the dataset: [Animal Crossing Villagers Dataset](https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv).\n",
    "- I asked how to check the dataset for column names and basic statistics using Python and the pandas library.\n",
    "\n",
    "**Chatbot's Response**:\n",
    "- Chatbot provided a step-by-step guide on how to use Python and the pandas library to explore the dataset. \n",
    "- The steps included:\n",
    "  1. Loading the dataset from the URL using `pd.read_csv()`.\n",
    "  2. Viewing the column names with `df.columns`.\n",
    "  3. Checking the number of rows and columns using `df.shape`.\n",
    "  4. Displaying basic dataset information (non-null counts, data types) with `df.info()`.\n",
    "  5. Previewing the first few rows of the dataset using `df.head()`.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            row_n\n",
      "count  391.000000\n",
      "mean   239.902813\n",
      "std    140.702672\n",
      "min      2.000000\n",
      "25%    117.500000\n",
      "50%    240.000000\n",
      "75%    363.500000\n",
      "max    483.000000\n"
     ]
    }
   ],
   "source": [
    "summary = df.describe()\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "species\n",
      "cat         23\n",
      "rabbit      20\n",
      "frog        18\n",
      "squirrel    18\n",
      "duck        17\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get counts of unique values in a specific column, e.g., 'species'\n",
    "value_counts = df['species'].value_counts()\n",
    "print(value_counts.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Personality Counts:\n",
      "personality\n",
      "lazy      60\n",
      "normal    59\n",
      "cranky    55\n",
      "snooty    55\n",
      "jock      55\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get value counts for another categorical column, e.g., 'personality'\n",
    "personality_counts = df['personality'].value_counts()\n",
    "\n",
    "print(\"\\nPersonality Counts:\")\n",
    "print(personality_counts.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Summary of Interactions with Chatbot Regarding Animal Crossing Dataset Analysis\n",
    "\n",
    "**Objective**: I aimed to understand how to provide simple summaries of the columns in a dataset about Animal Crossing characters using Python's pandas library. Specifically, I was looking for guidance on using the `df.describe()` and `df['column'].value_counts()` methods.\n",
    "\n",
    "---\n",
    "\n",
    "**Interaction 1**: \n",
    "- I asked for guidance on how to use two pandas methods: `df.describe()` for numeric summaries and `df['column'].value_counts()` for summarizing categorical columns.\n",
    "\n",
    "**Chatbot's Response**:\n",
    "- Chatbot provided detailed code examples and explanations on how to apply both methods in Python:\n",
    "\n",
    "### 1. **Using `df.describe()`**:\n",
    "   - Provides a statistical summary of numeric columns in the dataset, including measures like count, mean, standard deviation, min, max, and percentiles.\n",
    "   - Example code:\n",
    "\n",
    "   ```python\n",
    "   import pandas as pd\n",
    "\n",
    "   # Load the dataset\n",
    "   url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "   df = pd.read_csv(url)\n",
    "\n",
    "   # Get a statistical summary of numeric columns\n",
    "   summary = df.describe()\n",
    "   print(summary)\n",
    "   ```\n",
    "\n",
    "   **Output Explanation**:\n",
    "   - Count, mean, std, min, and percentiles for numeric data columns.\n",
    "\n",
    "### 2. **Using `df['column'].value_counts()`**:\n",
    "   - Provides a count of unique values in a specified column, useful for categorical data like species or personality traits.\n",
    "   - Example code:\n",
    "\n",
    "   ```python\n",
    "   # Get counts of unique values in a specific column, e.g., 'species'\n",
    "   value_counts = df['species'].value_counts()\n",
    "   print(value_counts)\n",
    "   ```\n",
    "\n",
    "   **Output Explanation**:\n",
    "   - Displays each unique value in the 'species' column and the corresponding count of occurrences.\n",
    "\n",
    "### 3. **Comprehensive Example**:\n",
    "   - A demonstration on how to use both methods together, summarizing numeric columns and providing counts of unique values for categorical columns like 'species' and 'personality'.\n",
    "\n",
    "   ```python\n",
    "   # Describe all numeric columns\n",
    "   numeric_summary = df.describe()\n",
    "\n",
    "   # Get value counts for a categorical column, e.g., 'species'\n",
    "   species_counts = df['species'].value_counts()\n",
    "\n",
    "   # Get value counts for another categorical column, e.g., 'personality'\n",
    "   personality_counts = df['personality'].value_counts()\n",
    "\n",
    "   print(\"Numeric Summary:\")\n",
    "   print(numeric_summary)\n",
    "\n",
    "   print(\"\\nSpecies Counts:\")\n",
    "   print(species_counts)\n",
    "\n",
    "   print(\"\\nPersonality Counts:\")\n",
    "   print(personality_counts)\n",
    "   ```\n",
    "\n",
    "**Summary**:\n",
    "Through this interaction, I gained an understanding of how to use `df.describe()` to summarize numeric columns and `df['column'].value_counts()` to summarize categorical data. The examples provided allowed me to see how these methods can be applied to the Animal Crossing dataset, making it easier to analyze the characters' traits and distributions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (891, 15)\n",
      "\n",
      "Dataset info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   survived     891 non-null    int64  \n",
      " 1   pclass       891 non-null    int64  \n",
      " 2   sex          891 non-null    object \n",
      " 3   age          714 non-null    float64\n",
      " 4   sibsp        891 non-null    int64  \n",
      " 5   parch        891 non-null    int64  \n",
      " 6   fare         891 non-null    float64\n",
      " 7   embarked     889 non-null    object \n",
      " 8   class        891 non-null    object \n",
      " 9   who          891 non-null    object \n",
      " 10  adult_male   891 non-null    bool   \n",
      " 11  deck         203 non-null    object \n",
      " 12  embark_town  889 non-null    object \n",
      " 13  alive        891 non-null    object \n",
      " 14  alone        891 non-null    bool   \n",
      "dtypes: bool(2), float64(2), int64(4), object(7)\n",
      "memory usage: 92.4+ KB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nDataset info:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (891, 15)\n",
      "\n",
      "Describe output:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         survived      pclass         age       sibsp       parch        fare\n",
       "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
       "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
       "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
       "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
       "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
       "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
       "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nDescribe output:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of Discrepancies\n",
    "\n",
    "\n",
    "### (a) Number of Columns\n",
    "\n",
    "- `df.shape[1]` shows the total number of columns in the dataset.\n",
    "- `df.describe()` only includes numeric columns by default.\n",
    "\n",
    "Discrepancy: `df.describe()` analyzes fewer columns than the total number in `df.shape[1]` because it excludes non-numeric columns like 'sex', 'embarked', etc.\n",
    "\n",
    "### (b) Values in the \"count\" Column\n",
    "\n",
    "- `df.shape[0]` shows the total number of rows in the dataset.\n",
    "- The \"count\" row in `df.describe()` shows the number of non-missing values for each numeric column.\n",
    "\n",
    "Discrepancy: If there are missing values in numeric columns, the \"count\" values in `df.describe()` will be less than the total number of rows shown by `df.shape[0]`.\n",
    "\n",
    "To verify this, we can check for missing values:\n",
    "\n",
    "```python\n",
    "print(df.isnull().sum())\n",
    "```\n",
    "\n",
    "This will show the number of missing values in each column. Columns with missing values will have counts in `df.describe()` that are less than the total number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary: Attributes vs Methods in Python\n",
    "\n",
    "In Python, attributes and methods are two different features of objects:\n",
    "\n",
    "1. **Attributes**:\n",
    "   - Represent characteristics or states of an object\n",
    "   - Don't use parentheses ()\n",
    "   - Provide information directly without computation\n",
    "   - Example: `df.shape` gives the dimensions of a DataFrame immediately\n",
    "\n",
    "2. **Methods**:\n",
    "   - Are actions or behaviors that an object can perform\n",
    "   - Use parentheses () to call them\n",
    "   - Usually perform some calculation or operation\n",
    "   - Example: `df.describe()` computes and returns a statistical summary\n",
    "\n",
    "This distinction is similar to the difference between constants and functions in mathematics. Attributes are like constants, providing fixed information, while methods are like functions, taking inputs (sometimes implied) and producing outputs.\n",
    "\n",
    "In programming, methods are essentially functions associated with specific objects. Using parentheses () to call a method indicates we're executing this function, similar to how we use parentheses in mathematics to show we're applying a function to a value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Interactions with Chatbot Regarding Attributes and Methods in Python\n",
    "\n",
    "**Objective**: I wanted to understand the difference between attributes like `df.shape` and methods like `df.describe()` in Python. Additionally, I was interested in how this concept relates to the difference between functions in programming and functions in mathematics.\n",
    "\n",
    "---\n",
    "\n",
    "**Interaction 1**: \n",
    "- I asked for an explanation of why attributes like `df.shape` donâ€™t require parentheses, while methods like `df.describe()` do.\n",
    "  \n",
    "**Chatbot's Response**:\n",
    "- Chatbot provided a detailed explanation, breaking down the difference between **attributes** and **methods** in Python:\n",
    "\n",
    "### 1. **Attributes**:\n",
    "   - Attributes are properties or characteristics of an object that provide information about it.\n",
    "   - They do not require parentheses because they represent data, not actions.\n",
    "   - Example: `df.shape` gives the dimensions (rows, columns) of the DataFrame.\n",
    "\n",
    "### 2. **Methods**:\n",
    "   - Methods are functions that belong to an object and perform specific actions or behaviors.\n",
    "   - They require parentheses, even when no arguments are passed, because they execute some computation or operation.\n",
    "   - Example: `df.describe()` computes and returns a summary of the numeric columns in the DataFrame.\n",
    "\n",
    "### 3. **Relationship to Functions in Mathematics vs. Programming**:\n",
    "   - In **mathematics**, functions map inputs to outputs (e.g., \\( f(x) = x^2 \\)).\n",
    "   - In **programming**, functions (and methods) execute blocks of code and can return results. Parentheses are used to call these functions.\n",
    "   - **Attributes** are like properties of an object, while **methods** are akin to functions that perform actions or calculations.\n",
    "\n",
    "---\n",
    "\n",
    "**Summary**:\n",
    "Through this interaction, I learned that **attributes** represent object properties and donâ€™t require parentheses, while **methods** perform actions and do require parentheses. This distinction is key in understanding object behavior in Python, and it mirrors the difference between **functions in programming** (which execute tasks) and **functions in mathematics** (which map inputs to outputs).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Qustion 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hereâ€™s a overview of the summary statistics from `df.describe()`:\n",
    "\n",
    "- **Count** (`count`): Number of non-null values in the column.\n",
    "- **Mean** (`mean`): Average of the values.\n",
    "- **Standard Deviation** (`std`): Measure of the dispersion or spread of values.\n",
    "- **Minimum** (`min`): Smallest value.\n",
    "- **25th Percentile** (`25%`): Value below which 25% of the data falls (first quartile).\n",
    "- **Median** (`50%`): Middle value when sorted (second quartile).\n",
    "- **75th Percentile** (`75%`): Value below which 75% of the data falls (third quartile).\n",
    "- **Maximum** (`max`): Largest value.\n",
    "\n",
    "**Handling Missing Values**: `df.describe()` excludes missing values (NaNs) from its calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>391.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>239.902813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>140.702672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>117.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            row_n\n",
       "count  391.000000\n",
       "mean   239.902813\n",
       "std    140.702672\n",
       "min      2.000000\n",
       "25%    117.500000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Get summary statistics\n",
    "summary = df.describe()\n",
    "summary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Interactions with Chatbot Regarding Summary Statistics in Pandas\n",
    "\n",
    "**Objective**: I wanted detailed explanations for the summary statistics provided by `df.describe()` in pandas, as well as clarification on how these statistics handle missing values.\n",
    "\n",
    "---\n",
    "\n",
    "**Interaction 1**: \n",
    "- I asked for definitions of key summary statistics generated by `df.describe()`, including 'count', 'mean', 'std', 'min', '25%', '50%', '75%', and 'max'.\n",
    "\n",
    "**Chatbot's Response**:\n",
    "- Chatbot provided detailed definitions and examples for each statistic:\n",
    "\n",
    "### 1. **Count**:\n",
    "   - Number of non-null values in each column.\n",
    "   \n",
    "### 2. **Mean**:\n",
    "   - The arithmetic average of the column values.\n",
    "\n",
    "### 3. **Standard Deviation (std)**:\n",
    "   - A measure of the spread or variability of the column values.\n",
    "\n",
    "### 4. **Minimum (min)**:\n",
    "   - The smallest value in the column.\n",
    "\n",
    "### 5. **25th Percentile (25%)**:\n",
    "   - The value below which 25% of the data falls (First quartile).\n",
    "\n",
    "### 6. **Median (50%)**:\n",
    "   - The middle value when the data is sorted (50th percentile).\n",
    "\n",
    "### 7. **75th Percentile (75%)**:\n",
    "   - The value below which 75% of the data falls (Third quartile).\n",
    "\n",
    "### 8. **Maximum (max)**:\n",
    "   - The largest value in the column.\n",
    "\n",
    "### Handling Missing Values:\n",
    "- **Explanation**: `df.describe()` excludes missing values (NaNs) from its calculations. Only non-null values are considered, and the count is reduced by the number of missing entries.\n",
    "\n",
    "### Example Code:\n",
    "- Chatbot provided Python code to demonstrate how to obtain these statistics and handle missing values:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"your_data.csv\")\n",
    "\n",
    "summary = df.describe()\n",
    "print(summary.loc['count'])\n",
    "print(summary.loc['mean'])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Summary**:\n",
    "Through this interaction, I gained an understanding of the various summary statistics provided by `df.describe()` in pandas and how these statistics treat missing data. I now know that `df.describe()` focuses on non-null values for its calculations and provides key insights into the distribution of the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1. Examples of when using df.dropna() might be preferred over del df['col'] for handling missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame after dropping rows with missing values:\n",
      "     A    B    C\n",
      "3  4.0  4.0  4.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Example DataFrame\n",
    "data = {\n",
    "    'A': [1, 2, None, 4],\n",
    "    'B': [None, 2, 3, 4],\n",
    "    'C': [1, None, 3, 4]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Drop rows with any missing values\n",
    "cleaned_df = df.dropna()\n",
    "\n",
    "print(\"DataFrame after dropping rows with missing values:\")\n",
    "print(cleaned_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame after deleting column 'B':\n",
      "     A    C\n",
      "0  1.0  1.0\n",
      "1  2.0  NaN\n",
      "2  NaN  3.0\n",
      "3  4.0  4.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example DataFrame\n",
    "data = {\n",
    "    'A': [1, 2, None, 4],\n",
    "    'B': [None, 2, 3, 4],\n",
    "    'C': [1, None, 3, 4]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Drop a specific column\n",
    "del df['B']\n",
    "\n",
    "print(\"DataFrame after deleting column 'B':\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Summary\n",
    "\n",
    "- **Use `df.dropna()`** when you need to handle missing data by removing rows or columns with NaN values, ensuring that the remaining data is complete.\n",
    "- **Use `del df['col']`** when you want to completely remove a column that is no longer needed or is not useful for your analysis, regardless of whether it contains missing values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 7.2 When might del df['col'] be a better choice than df.dropna() for dealing with missing data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame after deleting column 'ID':\n",
      "   Feature1  Feature2\n",
      "0      10.0       NaN\n",
      "1      20.0      15.0\n",
      "2       NaN      25.0\n",
      "3      40.0      35.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example DataFrame\n",
    "data = {\n",
    "    'ID': [1, 2, 3, 4],\n",
    "    'Feature1': [10, 20, None, 40],\n",
    "    'Feature2': [None, 15, 25, 35]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Remove irrelevant column 'ID'\n",
    "del df['ID']\n",
    "\n",
    "print(\"DataFrame after deleting column 'ID':\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame after deleting column 'B':\n",
      "     A  C\n",
      "0  1.0  1\n",
      "1  2.0  2\n",
      "2  NaN  3\n",
      "3  4.0  4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example DataFrame\n",
    "data = {\n",
    "    'A': [1, 2, None, 4],\n",
    "    'B': [None, None, None, None],  # Column with many missing values\n",
    "    'C': [1, 2, 3, 4]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Remove column 'B' with too many missing values\n",
    "del df['B']\n",
    "\n",
    "print(\"DataFrame after deleting column 'B':\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Summary\n",
    "\n",
    "- **`del df['col']`** is better when you need to remove a column entirely because it is irrelevant, has too many missing values, or contains sensitive information.\n",
    "- **`df.dropna()`** is suitable when you want to handle missing values by removing rows or columns with NaNs, while keeping other useful data intact.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.Why might it be important to use del df['col'] before df.dropna() when both are needed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame after cleaning:\n",
      "     A  C    D\n",
      "3  4.0  4  4.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Large DataFrame with unnecessary columns\n",
    "data = {\n",
    "    'A': [1, 2, None, 4],\n",
    "    'B': [None, None, None, None],  # Unnecessary column\n",
    "    'C': [1, 2, 3, 4],\n",
    "    'D': [None, None, None, 4]  # Another column with missing values\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# First remove the unnecessary column\n",
    "del df['B']\n",
    "\n",
    "# Then remove rows with any missing values\n",
    "cleaned_df = df.dropna()\n",
    "\n",
    "print(\"DataFrame after cleaning:\")\n",
    "print(cleaned_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "- **Explanation**: Removing unnecessary columns with `del df['col']` reduces the size of the DataFrame before performing operations like `df.dropna()`. This can improve performance by reducing the computational load, as `df.dropna()` will have to process fewer columns.\n",
    "- **Benefit**: Faster execution time and lower memory usage during the data cleaning process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Justification for choosing between del df['col'] and df.dropna() based on the situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape: (391, 11)\n",
      "Missing values:\n",
      " row_n           0\n",
      "id              1\n",
      "name            0\n",
      "gender          0\n",
      "species         0\n",
      "birthday        0\n",
      "personality     0\n",
      "song           11\n",
      "phrase          0\n",
      "full_id         0\n",
      "url             0\n",
      "dtype: int64\n",
      "Final shape: (379, 9)\n",
      "      name  gender    species birthday personality         song    phrase  \\\n",
      "0  Admiral    male       bird     1-27      cranky   Steep Hill   aye aye   \n",
      "1  Agent S  female   squirrel      7-2       peppy      DJ K.K.  sidekick   \n",
      "2    Agnes  female        pig     4-21        uchi   K.K. House   snuffle   \n",
      "3       Al    male    gorilla    10-18        lazy   Steep Hill   Ayyeeee   \n",
      "4  Alfonso    male  alligator      6-9        lazy  Forest Life  it'sa me   \n",
      "\n",
      "            full_id                                                url  \n",
      "0  villager-admiral  https://villagerdb.com/images/villagers/thumb/...  \n",
      "1  villager-agent-s  https://villagerdb.com/images/villagers/thumb/...  \n",
      "2    villager-agnes  https://villagerdb.com/images/villagers/thumb/...  \n",
      "3       villager-al  https://villagerdb.com/images/villagers/thumb/...  \n",
      "4  villager-alfonso  https://villagerdb.com/images/villagers/thumb/...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.isna().sum()\n",
    "# Print initial shape\n",
    "print(\"Initial shape:\", df.shape)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values:\\n\", df.isnull().sum())\n",
    "\n",
    "# Remove columns with too many missing values (e.g., more than 50%)\n",
    "cols_to_drop = df.columns[df.isnull().mean() > 0.5]\n",
    "df_clean = df.drop(columns=cols_to_drop)\n",
    "\n",
    "# Remove rows with any remaining missing values\n",
    "df_clean = df_clean.dropna()\n",
    "# Remove id column\n",
    "del df_clean['id']\n",
    "del df_clean['row_n']\n",
    "\n",
    "# Print final shape\n",
    "print(\"Final shape:\", df_clean.shape)\n",
    "print(df_clean.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Justification**: \n",
    "I first removed columns with more than 50% missing values to preserve as much data as possible. \n",
    "Then, I removed any remaining rows with missing values to ensure a complete dataset for analysis.\n",
    "After these steps, I was left with a clean dataset that could be used for further exploration and modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Interactions with Chatbot Regarding `del df['col']` vs. `df.dropna()` in Pandas\n",
    "\n",
    "**Objective**: I wanted to understand when using `del df['col']` is more appropriate than `df.dropna()` for handling missing data, and why it might be important to use `del df['col']` before `df.dropna()` in certain situations.\n",
    "\n",
    "---\n",
    "\n",
    "**Interaction 1**:\n",
    "- I asked when `del df['col']` is a better choice than `df.dropna()` for dealing with missing data.\n",
    "\n",
    "**Chatbot's Response**:\n",
    "- **`del df['col']`** is preferable in these scenarios:\n",
    "   1. **Irrelevant or Redundant Columns**: When a column is irrelevant to the analysis, even if it contains no missing values.\n",
    "   2. **Columns with Too Many Missing Values**: When a column has an overwhelmingly high percentage of missing data, making it impractical to clean or impute.\n",
    "   3. **Data Privacy or Compliance**: When a column contains sensitive information and needs to be removed for privacy reasons.\n",
    "\n",
    "- Example code for removing irrelevant or redundant columns using `del df['col']` was provided.\n",
    "\n",
    "---\n",
    "\n",
    "**Interaction 2**:\n",
    "- I asked why it might be important to use `del df['col']` before `df.dropna()` when both are needed.\n",
    "\n",
    "**Chatbot's Response**:\n",
    "- **Reasons for using `del df['col']` before `df.dropna()`**:\n",
    "   1. **Improve Performance and Efficiency**: Removing unnecessary columns first reduces the DataFrame size, improving performance during subsequent operations like `df.dropna()`.\n",
    "   2. **Avoid Processing Redundant Data**: Focusing only on relevant columns simplifies and speeds up data cleaning.\n",
    "   3. **Simplify Data Cleaning Process**: Reducing complexity ensures a more streamlined and efficient cleaning process.\n",
    "\n",
    "- Example code demonstrated the order of using `del df['col']` followed by `df.dropna()`.\n",
    "\n",
    "---\n",
    "\n",
    "**Summary**:\n",
    "Through this interaction, I learned that using `del df['col']` is advantageous when dealing with irrelevant or redundant columns, handling columns with too many missing values, or ensuring data privacy. Additionally, using `del df['col']` before `df.dropna()` can improve performance, reduce redundant processing, and simplify the data cleaning process.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation: ChatBot vs Google for Code Troubleshooting\n",
    "\n",
    "After intentionally introducing various errors into my code and attempting to resolve them using both a ChatBot and Google searches, here's my assessment:\n",
    "\n",
    "1. **Import Error**: Both ChatBot and Google were equally helpful. The solution was straightforward, and both quickly identified the missing import statement.\n",
    "\n",
    "2. **File Not Found Error**: Google was slightly more helpful here. It provided a wider range of potential causes (typos, wrong directory, etc.) while the ChatBot focused mainly on the typo in the filename.\n",
    "\n",
    "3. **Variable Name Error**: The ChatBot was more helpful in this case. It explained the concept of variable scope and suggested checking for typos or incorrect variable names. Google results were more generic and required more sifting through irrelevant information.\n",
    "\n",
    "4. **Syntax Error (Missing Parenthesis)**: Both were equally effective. This is a common error with a straightforward solution that both sources easily identified.\n",
    "\n",
    "5. **Function Name Error**: The ChatBot was notably more helpful here. It not only identified the typo but also explained the correct method names in pandas. Google results were mixed and required more time to find the specific answer.\n",
    "\n",
    "6. **Column Name Error**: This was a tie. Both sources quickly identified the issue of case sensitivity in column names. However, the ChatBot provided a more tailored explanation for pandas DataFrames.\n",
    "\n",
    "7. **String Quotation Error**: The ChatBot was more helpful in explaining why quotes are necessary for column names in pandas. Google provided the solution but with less context specific to pandas.\n",
    "\n",
    "Overall, I found the ChatBot to be slightly more helpful, especially for pandas-specific issues. It provided more contextualized answers and was able to understand the specific pandas-related nuances of my questions. However, Google was better for general Python errors and offered a broader range of potential solutions.\n",
    "\n",
    "The ChatBot excelled in providing explanations along with solutions, which helped me understand why the errors occurred. Google, on the other hand, was faster for simple, common errors and provided a wider variety of sources and perspectives.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Summary of Interactions With chat bot\n",
    "\n",
    "1. **Introduction and Objective**:\n",
    "   - You aimed to perform some initial summary analysis on the Titanic dataset, which you downloaded from the URL: https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv. You asked for help understanding the code and analysis involved.\n",
    "\n",
    "2. **Understanding `df.groupby('col1')['col2'].describe()`**:\n",
    "   - We discussed that `df.groupby('col1')['col2'].describe()` groups a DataFrame by `col1`, then calculates descriptive statistics (count, mean, standard deviation, etc.) for `col2` within each group.\n",
    "   - We used an example where we grouped by `pclass` and described the `age` column to get statistics for different passenger classes.\n",
    "\n",
    "3. **Differences Between `df.describe()` and `df.groupby('col1')['col2'].describe()`**:\n",
    "   - The key difference is the scope: `df.describe()` computes statistics for the entire DataFrame, while `df.groupby('col1')['col2'].describe()` provides the same statistics but within each subgroup (defined by `col1`).\n",
    "   \n",
    "4. **Common Coding Issues and Error Fixes**:\n",
    "   - **Importing pandas**: You forgot to include `import pandas as pd`, leading to a `NameError: name 'pd' is not defined`. We fixed it by adding the import statement at the top of the code.\n",
    "   - **Incorrect File Name**: You encountered a `FileNotFoundError` due to mistyping the file name as `titanics.csv` instead of `titanic.csv`. The solution was to correct the file name.\n",
    "   - **Using DataFrame Before Assignment**: You received a `NameError` due to referencing `DF` instead of `df`. The fix was to use the correct variable name (`df`).\n",
    "   - **SyntaxError (Missing Parenthesis)**: The error `SyntaxError: unexpected EOF while parsing` occurred because you missed a closing parenthesis in `pd.read_csv()`. We fixed it by ensuring the parentheses were properly closed.\n",
    "   - **Misspelled Method**: You mistakenly called `df.describle()` instead of `df.describe()`, leading to an `AttributeError`. We fixed this by correcting the method name.\n",
    "   - **KeyError: 'sex'**: The error occurred because the column name `sex` was not recognized. We checked the actual column names using `df.columns`, and found that the column exists but needed correct referencing.\n",
    "   - **NameError: name 'sex' is not defined**: This happened because you tried to reference the column without quotes. We fixed it by enclosing `'sex'` in quotes, correctly identifying the column in the DataFrame.\n",
    "\n",
    "5. **Final Solution**:\n",
    "   - We successfully executed the operation `df.groupby('sex')['age'].describe()` after resolving the errors, providing descriptive statistics of the `age` column grouped by `sex`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9\n",
    "YES"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
